# TensorRT-Yolov3-model

Deploy model was trained from  [mobilenet-yolov3](https://github.com/eric612/MobileNet-YOLO), inference speed was listed [here](https://github.com/eric612/Jetson-nano-benchmark)

## Inference project

I modify some code from lewes's project and update on [fork](https://github.com/eric612/TensorRT-Yolov3) 

Note : mobilenet-yolov3-lite need change anchors config , you need replace the config [files](/mobilenet-yolov3-lite/) and re-build project
